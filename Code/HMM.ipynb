{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9dc6dbe-def3-4688-8da1-21fd873055cc",
   "metadata": {},
   "source": [
    "Hidden Markov Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0274b7aa-bbad-4942-b5ba-0f960444b515",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing needed packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "import hmmlearn\n",
    "import pprint\n",
    "import scipy\n",
    "import sklearn.cluster\n",
    "from sklearn.cluster import KMeans\n",
    "from random import shuffle\n",
    "from scipy import linalg\n",
    "from hmmlearn import hmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b04b3f03-cf78-48af-988d-c80df318fa8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Hidden_Markov_Model:\n",
    "    \n",
    "    def __init__(self,n_states,A,B,initial_distribution=None):\n",
    "        self.n = n_states\n",
    "        self.A = A\n",
    "        self.B = B\n",
    "        if initial_distribution is None:\n",
    "            self.initial_distribution = np.linalg.matrix_power(self.A,2000)[0]\n",
    "        else:\n",
    "            self.initial_distribution = initial_distribution\n",
    "            \n",
    "    \n",
    "    def forward_backward(self,observations):\n",
    "        \n",
    "        alpha = np.zeros((observations.shape[0], self.A.shape[0]))\n",
    "        beta = np.zeros((observations.shape[0], self.A.shape[0]))\n",
    "        \n",
    "        alpha[0, :] = self.initial_distribution * self.B[:, observations[0]]\n",
    "        beta[observations.shape[0] - 1] = np.ones((self.A.shape[0]))\n",
    "\n",
    "        for t in range(1, observations.shape[0]):\n",
    "            for j in range(self.A.shape[0]):\n",
    "                alpha[t, j] = alpha[t - 1].dot(self.A[:, j]) * self.B[j, observations[t]]\n",
    "                \n",
    "        for t in range(observations.shape[0] - 2, -1, -1):\n",
    "            for j in range(self.A.shape[0]):\n",
    "                beta[t, j] = np.dot((beta[t + 1] * self.B[:, observations[t + 1]]),self.A[j, :])\n",
    "\n",
    "\n",
    "        return alpha,beta,np.sum(alpha[-1])\n",
    "    \n",
    "    @staticmethod\n",
    "    def forward_algorithm(observations,A,B,initial_distribution):\n",
    "        alpha = np.zeros((observations.shape[0], A.shape[0]))\n",
    "        alpha[0, :] = initial_distribution * B[:, observations[0]]\n",
    "\n",
    "        for t in range(1, observations.shape[0]):\n",
    "            for j in range(A.shape[0]):\n",
    "                alpha[t, j] = alpha[t - 1].dot(A[:, j]) * B[j, observations[t]]\n",
    "\n",
    "        return alpha\n",
    "    \n",
    "    @staticmethod\n",
    "    def backward_algorithm(observations,A,B):\n",
    "        beta = np.zeros((observations.shape[0], A.shape[0]))\n",
    "        beta[observations.shape[0] - 1] = np.ones((A.shape[0]))\n",
    "\n",
    "        for t in range(observations.shape[0] - 2, -1, -1):\n",
    "            for j in range(A.shape[0]):\n",
    "                beta[t, j] = (beta[t + 1] * B[:, observations[t + 1]]).dot(A[j, :])\n",
    "\n",
    "        return beta\n",
    "\n",
    "        \n",
    "    \n",
    "    def viterbi(self,observations):\n",
    "        \n",
    "        T = int(observations.shape[0])\n",
    "        M = int(self.A.shape[0])\n",
    "\n",
    "        gamma = np.zeros((T,M))\n",
    "        psi = np.zeros((1,T))\n",
    "        gamma[0,:] = self.initial_distribution * self.B[:, observations[0]]\n",
    "        psi[0] = np.argmax(gamma[0,:])\n",
    "\n",
    "        for i in range(1,T):\n",
    "            gamma[i,:] = np.max(gamma[i-1,:])*self.A[np.argmax(gamma[i-1,:]),:]*self.B[:,observations[i]]\n",
    "            psi[:,i] = np.argmax(gamma[i,:])\n",
    "        \n",
    "        psi = psi.astype(int)\n",
    "            \n",
    "        return gamma\n",
    "    \n",
    "    def baum_welch(self,observations,n_iter=1000):\n",
    "        \n",
    "        A = self.A\n",
    "        B = self.B\n",
    "        M = A.shape[0]\n",
    "        T = len(observations)\n",
    "        initial_distribution = self.initial_distribution\n",
    "\n",
    "        for n in range(n_iter):\n",
    "            \n",
    "            alpha = Hidden_Markov_Model.forward_algorithm(observations,A,B,initial_distribution)\n",
    "            beta = Hidden_Markov_Model.backward_algorithm(observations,A,B)\n",
    "           \n",
    "            Eta = np.zeros((M, M, T - 1))\n",
    "            \n",
    "            \n",
    "            for t in range(T - 1):\n",
    "                den = np.dot(np.dot(alpha[t, :].T, A) * B[:, observations[t + 1]].T, beta[t + 1, :])\n",
    "                for i in range(M):\n",
    "                    num = alpha[t, i] * A[i, :] * B[:, observations[t + 1]].T * beta[t + 1, :].T\n",
    "                    Eta[i, :, t] = num / den\n",
    "\n",
    "            gamma = np.sum(Eta, axis=1)\n",
    "            A = np.sum(Eta, 2) / np.sum(gamma, axis=1).reshape((-1, 1))\n",
    "\n",
    "            gamma = np.hstack((gamma, np.sum(Eta[:, :, T - 2], axis=0).reshape((-1, 1))))\n",
    "\n",
    "            K = B.shape[1]\n",
    "            den = np.sum(gamma, axis=1)\n",
    "            for l in range(K):\n",
    "                B[:, l] = np.sum(gamma[:, observations == l], axis=1)\n",
    "\n",
    "            B = np.divide(B, den.reshape((-1, 1)))\n",
    "\n",
    "        return A,B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61a2e0e2-f103-432b-a6fc-613a70184dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FDS:\n",
    "    def __init__(self,n_states,n_observations,Observations):\n",
    "        self.n_states = n_states\n",
    "        self.n_observations = n_observations\n",
    "        self.Observations = Observations\n",
    "        self.clusters = self.Kmeans()[0]\n",
    "        self.pi,self.A,self.B = self.probability_matrices()\n",
    "        self.train_HMM()\n",
    "        \n",
    "    def Kmeans(self,value=None): # bayesian \n",
    "        kmeans = KMeans(n_clusters=self.n_observations,random_state=140)\n",
    "        kmeans.fit(self.Observations.reshape(-1,1))\n",
    "        if value is not None:\n",
    "            v = kmeans.predict([[value]])[0]\n",
    "        else:\n",
    "            v = None\n",
    "        \n",
    "        return kmeans.labels_,v\n",
    "        \n",
    "        \n",
    "    def probability_matrices(self):\n",
    "        pi_prob = np.zeros(self.n_states)\n",
    "        transition_prob = np.zeros((self.n_states,self.n_states))\n",
    "        emission_prob = np.zeros((self.n_states,self.n_observations))\n",
    "\n",
    "        for i in range(self.n_states):\n",
    "            pi_prob[i] = 1 / self.n_states\n",
    "\n",
    "        for i in range(self.n_states):\n",
    "            for j in range(self.n_states):\n",
    "                transition_prob[i][j] = 1 / self.n_states\n",
    "\n",
    "        for i in range(self.n_states):\n",
    "            for j in range(self.n_observations):\n",
    "                emission_prob[i][j] = 1 / self.n_observations\n",
    "\n",
    "        return pi_prob, transition_prob, emission_prob\n",
    "    \n",
    "    def train_HMM(self):\n",
    "        Hmm = Hidden_Markov_Model(self.n_states,self.A,self.B,initial_distribution=self.pi)\n",
    "        self.A,self.B = Hmm.baum_welch(self.clusters)\n",
    "        self.pi = np.linalg.matrix_power(self.A,2000)[0]\n",
    "        Hmm2 = Hidden_Markov_Model(self.n_states,self.A,self.B,initial_distribution=self.pi)\n",
    "        self.alpha = Hmm2.forward_backward(self.clusters[-10:])[2]\n",
    "    \n",
    "    def test(self,value):\n",
    "        self.clusters = self.Kmeans()[0]\n",
    "        self.train_HMM()\n",
    "        clusters = np.append(self.clusters[-9:],self.Kmeans(value=value)[1])\n",
    "        #print(self.clusters,clusters)\n",
    "        Hmm2 = Hidden_Markov_Model(self.n_states,self.A,self.B,initial_distribution=self.pi)\n",
    "        alpha2 = Hmm2.forward_backward(clusters)[2]\n",
    "        threshold = 0.60\n",
    "        delta = (self.alpha-alpha2)/self.alpha\n",
    "        if delta >= threshold:\n",
    "            print(\"This Transaction is fraud\")\n",
    "        else:\n",
    "            print(\"This Transaction is not fraud\")\n",
    "            self.Observations = np.append(self.Observations,value)\n",
    "            #print(self.Observations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18c48f49-3603-4dd4-9959-59587265c5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Transactions = np.array([15999,975.3,19737,1028.25,599,2070,1152,149,729,591.56,50,599,499,3791.5,2070,1999,100,149,648]) # one person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28cd151e-83a5-4a1d-9fa8-f72a412354f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\Bayesian\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1332: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "fds=FDS(2,3,Transactions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1352e6ae-d6c5-4259-b26a-a10430ee969a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Anaconda\\envs\\Bayesian\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1332: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n",
      "d:\\Anaconda\\envs\\Bayesian\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1332: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This Transaction is not fraud\n"
     ]
    }
   ],
   "source": [
    "fds.test(718.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c091412-7089-4fc4-b95e-ee08b2d66b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "fds.test(974)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4412aa79-6d6d-43ad-bcf0-134a1e656fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fds.test(455)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e890bbd1-600c-4e00-b3a3-1d6aeb82ecad",
   "metadata": {},
   "outputs": [],
   "source": [
    "fds.test(13000) #initial testing -> security questions -> if not, then conclude it is really fraud"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27c6d31-f1e7-4879-a073-f973e71f8e2a",
   "metadata": {},
   "source": [
    "need calculation of precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3df2fe9-d515-45c0-b143-b5d30e3ad4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "THRESHOLD = 0.9\n",
    "STATES = 5\n",
    "CLUSTERS = 3\n",
    "STEPS = 200\n",
    "TEST_RANGE = 1000\n",
    "TERMINATE = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be2c2338-282f-4e28-a5ed-ad1223a471d0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'Source'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[1;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mSource\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclustering\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m KMeansClustering\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mSource\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdriver\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Driver\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mSource\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mhidden_markov_model\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m HMM\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'Source'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from Source.clustering import KMeansClustering\n",
    "from Source.driver import Driver\n",
    "from Source.hidden_markov_model import HMM\n",
    "\n",
    "from config import *\n",
    "\n",
    "\n",
    "def get_input():\n",
    "    while True:\n",
    "        new_transaction = input('Please add your new transaction : ')\n",
    "        if int(new_transaction) == TERMINATE:\n",
    "            break\n",
    "        new_transaction = k.predict(int(new_transaction))\n",
    "        new_observation = np.append(observations[1:], [new_transaction])\n",
    "\n",
    "        if h.detect_fraud(observations, new_observation, THRESHOLD):\n",
    "            print('Fraud')\n",
    "        else:\n",
    "            print('Normal')\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    d = Driver('C:/Users/LENOVO/OneDrive - De La Salle University - Manila/DLSU/3/Bayesian/Data/train_data.txt')\n",
    "\n",
    "    h = HMM(n_states=STATES, n_possible_observations=CLUSTERS)\n",
    "    k = KMeansClustering()\n",
    "\n",
    "    observations = k.run(d.get_data()[0:192])\n",
    "    h.train_model(observations=list(observations), steps=STEPS)\n",
    "\n",
    "    get_input()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "8bc106c813c4b4e0f0fadf80553f030a33b748b8c74a927efd6d8d1ec368eec8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
